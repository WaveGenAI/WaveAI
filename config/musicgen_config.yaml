model:
  num_codebooks: 4
  codebook_size: 2048
  hidden_size: 1024
  stereo: false
  decoder_depth: 24
  decoder_heads: 16
  rotary_emb: false

  memory_dim: 1024
  max_seq_length: 200
  
  vocab_size: 32128
  pad_token_id: 2048
  tokenizer: 'google/flan-t5-base'

data:
  dataset_id: 'WaveGenAI/audio'
  duration: 30
  max_prompt_length: 512
  max_lyrics_length: 512

train:
  max_epochs: 10
  accumulate_grad_batches: 32
  batch_size: 1
  gradient_clip_val: 1 
  warmup_steps: 200
  lr_max: 0.00095
  lr_min: 0.000001  
  test_model: true
  train_num_workers: 2
  val_num_workers: 1

inference:
  checkpoint_path: 
  top_k: 50
